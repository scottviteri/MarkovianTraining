\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{NEURIPS2020_1457c0d6}
\citation{lamparth2023analyzing,burns2024discovering,gurnee2024language}
\citation{Grabb2024.04.07.24305462,lamparth2024human,rivera2024escalation}
\citation{geiger2022inducing,geva2022transformer,meng2022locating,raukur2022toward,wang2022interpretability,lamparth2023analyzing,nanda2023progress}
\citation{nye2022show,wei2022chain}
\citation{turpin2023language}
\citation{lanham2023measuring}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{cobbe2021gsm8k}
\citation{wei2022chain,nye2022show}
\citation{eric_star2022,zelikman2024quietstar,deepseekai2025}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Refined illustration of the training method. Left: Single time-step process from Question to CoT to Answer. Right: Causal structure showing the generation of states from observations and previous states using the state update function $u_\theta (s'|o,s)$, and the prediction of observations from states using the policy $\pi (o|s)$. Observations are generated by the causal data distribution. In experiments, both $u_\theta $ and $\pi $ are Mistral 7B Instruct V0.2 or Llama 3.1 8B Instruct, but only the weights of $u_\theta $ are updated during training. The state update $u_\theta $ also involves concatenating the observation and state letting Mistral generate the next state's worth of tokens.}}{2}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:training-method-causal-final}{{1}{2}{Refined illustration of the training method. Left: Single time-step process from Question to CoT to Answer. Right: Causal structure showing the generation of states from observations and previous states using the state update function $u_\theta (s'|o,s)$, and the prediction of observations from states using the policy $\pi (o|s)$. Observations are generated by the causal data distribution. In experiments, both $u_\theta $ and $\pi $ are Mistral 7B Instruct V0.2 or Llama 3.1 8B Instruct, but only the weights of $u_\theta $ are updated during training. The state update $u_\theta $ also involves concatenating the observation and state letting Mistral generate the next state's worth of tokens}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Recipient-Specific Compression.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Contributions.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related_work}{{2}{2}{Related Work}{section.2}{}}
\citation{lanham2023measuring,turpin2023language}
\citation{zhou2023understanding}
\citation{rumelhart1986learning}
\citation{gu2022efficientlymodelinglongsequences}
\citation{gu2024mamba}
\citation{policy_gradient}
\citation{proto_pomdp1965}
\citation{karl2017deepvariationalbayesfilters}
\citation{krishnan2015deepkalmanfilters}
\citation{DBLP:journals/corr/ChungKDGCB15}
\citation{lyu2023faithful}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The log probability $\ln \pi (\text  {ans} \mid \text  {CoT})$ of the answer $ans$ given a $\text  {CoT}$, where the $\text  {CoT}$ is sampled from the trained weights $\text  {CoT} \sim u_\theta (\text  {CoT} \mid q, \text  {CoT}_{\text  {init}})$ and $\text  {CoT}'$ is sampled from the unmodified weights $\text  {CoT}' \sim u(\text  {CoT} \mid q, \text  {CoT}_{\text  {init}})$. We train to produce CoTs which are sufficient to predict the correct answer even without the original question, enforcing a text bottleneck in the language model's information flow, forcing the CoT to be causally load-bearing to production of the answer. This plot specifically depicts the training of Mistral 7B Instruct V0.2 on fifteen-term addition problems and their solutions. Because of high variance, we plot the point-wise maximum \emph  {over four runs} for each training technique.}}{3}{figure.caption.5}\protected@file@percent }
\newlabel{fig:loss}{{2}{3}{The log probability $\ln \pi (\text {ans} \mid \text {CoT})$ of the answer $ans$ given a $\text {CoT}$, where the $\text {CoT}$ is sampled from the trained weights $\text {CoT} \sim u_\theta (\text {CoT} \mid q, \text {CoT}_{\text {init}})$ and $\text {CoT}'$ is sampled from the unmodified weights $\text {CoT}' \sim u(\text {CoT} \mid q, \text {CoT}_{\text {init}})$. We train to produce CoTs which are sufficient to predict the correct answer even without the original question, enforcing a text bottleneck in the language model's information flow, forcing the CoT to be causally load-bearing to production of the answer. This plot specifically depicts the training of Mistral 7B Instruct V0.2 on fifteen-term addition problems and their solutions. Because of high variance, we plot the point-wise maximum \emph {over four runs} for each training technique}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Markovian Language Models and Informativeness}{3}{section.3}\protected@file@percent }
\newlabel{sec:MLM}{{3}{3}{Markovian Language Models and Informativeness}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Markovian Language Models (MLM)}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Data-Generating Distribution and Reward}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Informativeness Objective}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Methods}{5}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{5}{Methods}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Implementation as Question-Answer Pairs}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Reinforcement Learning Objectives}{5}{subsection.4.2}\protected@file@percent }
\newlabel{subsec:rl_objectives}{{4.2}{5}{Reinforcement Learning Objectives}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Threshold-based Expert Iteration (TEI)}{5}{subsubsection.4.2.1}\protected@file@percent }
\newlabel{subsubsec:tei}{{4.2.1}{5}{Threshold-based Expert Iteration (TEI)}{subsubsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Policy Gradient (PG)}{5}{subsubsection.4.2.2}\protected@file@percent }
\newlabel{subsubsec:pg}{{4.2.2}{5}{Policy Gradient (PG)}{subsubsection.4.2.2}{}}
\citation{hu2022lora}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Proximal Policy Optimization (PPO)}{6}{subsubsection.4.2.3}\protected@file@percent }
\newlabel{subsubsec:ppo}{{4.2.3}{6}{Proximal Policy Optimization (PPO)}{subsubsection.4.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Stability and Implementation Details}{6}{subsection.4.3}\protected@file@percent }
\newlabel{subsec:stability}{{4.3}{6}{Training Stability and Implementation Details}{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces GSM8K performance metrics over three separate training runs of Llama-3.1-8B-Instruct. The left plot shows the log probability that an untrained Llama assigns to the correct answer given the trained CoT --- $\ln \pi (\text  {ans}|\text  {CoT})$, and the right plot shows the proportion of CoTs in a batch which contain the answer verbatim. We use a smoothing window of size 100, explaining the multiplicity of possible y-values for ``Contains Answer''.}}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:gsm8k_performance}{{3}{7}{GSM8K performance metrics over three separate training runs of Llama-3.1-8B-Instruct. The left plot shows the log probability that an untrained Llama assigns to the correct answer given the trained CoT --- $\ln \pi (\text {ans}|\text {CoT})$, and the right plot shows the proportion of CoTs in a batch which contain the answer verbatim. We use a smoothing window of size 100, explaining the multiplicity of possible y-values for ``Contains Answer''}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{7}{section.5}\protected@file@percent }
\newlabel{sec:experiments}{{5}{7}{Experiments}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Multi-step Addition}{7}{subsection.5.1}\protected@file@percent }
\newlabel{subsec:solving}{{5.1}{7}{Multi-step Addition}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}GSM8K}{7}{subsection.5.2}\protected@file@percent }
\newlabel{subsec:gsm8k}{{5.2}{7}{GSM8K}{subsection.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Wikipedia}{7}{subsection.5.3}\protected@file@percent }
\newlabel{subsec:wikipedia}{{5.3}{7}{Wikipedia}{subsection.5.3}{}}
\citation{lanham2023measuring}
\citation{abdin2024phi3technicalreporthighly}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Impact of perturbations on CoT effectiveness with/without the original question. Three perturbation types shown: character deletion, front truncation, and random replacement. Higher values indicate stronger reliance on CoT when the question is absent, showing causal dependence rather than just improved accuracy.}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:perturbation}{{4}{8}{Impact of perturbations on CoT effectiveness with/without the original question. Three perturbation types shown: character deletion, front truncation, and random replacement. Higher values indicate stronger reliance on CoT when the question is absent, showing causal dependence rather than just improved accuracy}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Measuring Fragility of CoT}{8}{subsection.5.4}\protected@file@percent }
\newlabel{subsec:fragile}{{5.4}{8}{Measuring Fragility of CoT}{subsection.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Interpretability of CoT Generations}{8}{subsection.5.5}\protected@file@percent }
\newlabel{subsec:interp}{{5.5}{8}{Interpretability of CoT Generations}{subsection.5.5}{}}
\bibdata{neurips_2025}
\bibcite{abdin2024phi3technicalreporthighly}{{1}{2024}{{Abdin et~al.}}{{Abdin, Aneja, Awadalla, Awadallah, Awan, Bach, Bahree, Bakhtiari, Bao, et~al.}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Cross-model evaluation showing Llama-3.1-8B-Instruct's evaluation of Mistral's CoT quality throughout training on Wikipedia text prediction. The correlation between improvements in both models' evaluations suggests the learned reasoning patterns generalize across architectures rather than being model-specific artifacts. Each plot is averaged across 6 independent training runs.}}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:cross_eval}{{5}{9}{Cross-model evaluation showing Llama-3.1-8B-Instruct's evaluation of Mistral's CoT quality throughout training on Wikipedia text prediction. The correlation between improvements in both models' evaluations suggests the learned reasoning patterns generalize across architectures rather than being model-specific artifacts. Each plot is averaged across 6 independent training runs}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion and Limitations}{9}{section.6}\protected@file@percent }
\newlabel{sec:disc}{{6}{9}{Discussion and Limitations}{section.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Future Work.}{9}{section*.9}\protected@file@percent }
\bibcite{NEURIPS2020_1457c0d6}{{2}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, et~al.}}}
\bibcite{burns2024discovering}{{3}{2023}{{Burns et~al.}}{{Burns, Ye, Klein, and Steinhardt}}}
\bibcite{raukur2022toward}{{4}{2023}{{Casper et~al.}}{{Casper, Rauker, Ho, and Hadfield-Menell}}}
\bibcite{DBLP:journals/corr/ChungKDGCB15}{{5}{2015}{{Chung et~al.}}{{Chung, Kastner, Dinh, Goel, Courville, and Bengio}}}
\bibcite{cobbe2021gsm8k}{{6}{2021}{{Cobbe et~al.}}{{Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman}}}
\bibcite{deepseekai2025}{{7}{2025}{{DeepSeek-AI et~al.}}{{DeepSeek-AI, Guo, Yang, Zhang, Song, Zhang, Xu, et~al.}}}
\bibcite{geiger2022inducing}{{8}{2022}{{Geiger et~al.}}{{Geiger, Wu, Lu, Rozner, Kreiss, Icard, Goodman, and Potts}}}
\bibcite{geva2022transformer}{{9}{2022}{{Geva et~al.}}{{Geva, Caciularu, Wang, and Goldberg}}}
\bibcite{Grabb2024.04.07.24305462}{{10}{2024}{{Grabb et~al.}}{{Grabb, Lamparth, and Vasan}}}
\bibcite{gu2024mamba}{{11}{2024}{{Gu and Dao}}{{}}}
\bibcite{gu2022efficientlymodelinglongsequences}{{12}{2022}{{Gu et~al.}}{{Gu, Goel, and Ré}}}
\bibcite{gurnee2024language}{{13}{2024}{{Gurnee and Tegmark}}{{}}}
\bibcite{hu2022lora}{{14}{2022}{{Hu et~al.}}{{Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen}}}
\bibcite{karl2017deepvariationalbayesfilters}{{15}{2017}{{Karl et~al.}}{{Karl, Soelch, Bayer, and van~der Smagt}}}
\bibcite{krishnan2015deepkalmanfilters}{{16}{2015}{{Krishnan et~al.}}{{Krishnan, Shalit, and Sontag}}}
\bibcite{lamparth2023analyzing}{{17}{2023}{{Lamparth and Reuel}}{{}}}
\bibcite{lamparth2024human}{{18}{2024}{{Lamparth et~al.}}{{Lamparth, Corso, Ganz, Mastro, Schneider, and Trinkunas}}}
\bibcite{lanham2023measuring}{{19}{2023}{{Lanham et~al.}}{{Lanham, Chen, Radhakrishnan, Steiner, Denison, Hernandez, Li, Durmus, Hubinger, Kernion, Lukošiūtė, Nguyen, Cheng, Joseph, Schiefer, Rausch, Larson, McCandlish, Kundu, Kadavath, Yang, Henighan, Maxwell, Telleen-Lawton, Hume, Hatfield-Dodds, Kaplan, Brauner, Bowman, and Perez}}}
\bibcite{lyu2023faithful}{{20}{2023}{{Lyu et~al.}}{{Lyu, Havaldar, Stein, Zhang, Rao, Wong, Apidianaki, and Callison-Burch}}}
\bibcite{meng2022locating}{{21}{2022}{{Meng et~al.}}{{Meng, Bau, Andonian, and Belinkov}}}
\bibcite{nanda2023progress}{{22}{2023}{{Nanda et~al.}}{{Nanda, Chan, Lieberum, Smith, and Steinhardt}}}
\bibcite{nye2022show}{{23}{2022}{{Nye et~al.}}{{Nye, Andreassen, Gur-Ari, Michalewski, Austin, Bieber, Dohan, Lewkowycz, Bosma, Luan, Sutton, and Odena}}}
\bibcite{rivera2024escalation}{{24}{2024}{{Rivera et~al.}}{{Rivera, Mukobi, Reuel, Lamparth, Smith, and Schneider}}}
\bibcite{rumelhart1986learning}{{25}{1986}{{Rumelhart et~al.}}{{Rumelhart, Hinton, and Williams}}}
\bibcite{policy_gradient}{{26}{1999}{{Sutton et~al.}}{{Sutton, McAllester, Singh, and Mansour}}}
\bibcite{turpin2023language}{{27}{2023}{{Turpin et~al.}}{{Turpin, Michael, Perez, and Bowman}}}
\bibcite{wang2022interpretability}{{28}{2022}{{Wang et~al.}}{{Wang, Variengien, Conmy, Shlegeris, and Steinhardt}}}
\bibcite{wei2022chain}{{29}{2022}{{Wei et~al.}}{{Wei, Wang, Schuurmans, Bosma, brian ichter, Xia, Chi, Le, and Zhou}}}
\bibcite{eric_star2022}{{30}{2022}{{Zelikman et~al.}}{{Zelikman, Wu, Mu, and Goodman}}}
\bibcite{zelikman2024quietstar}{{31}{2024}{{Zelikman et~al.}}{{Zelikman, Harik, Shao, Jayasiri, Haber, and Goodman}}}
\bibcite{zhou2023understanding}{{32}{2023}{{Zhou et~al.}}{{Zhou, Zhou, Han, and Kambadur}}}
\bibcite{proto_pomdp1965}{{33}{1965}{{Åström, Karl Johan}}{{}}}
\bibstyle{plainnat}
\gdef \@abspage@last{20}
