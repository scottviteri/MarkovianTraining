{"task_type": "arithmetic", "model_type": "gpt2", "resume": false, "use_ei": null, "use_ppo": true, "cot_length": 5, "r": 0.9, "temperature": 1.0, "question_length": 50, "target_length": 50, "kl_penalty": 0.1, "gradient_accumulation_steps": 1, "batch_size": 1, "normalize_loss": true, "lr": 0.0001, "num_batches": 1, "ppo_epsilon": 0.2, "checkpoint_frequency": null, "weight_verification_freq": 10, "enable_weight_verification": false, "lora_rank": 8, "lora_alpha": 16, "debug_repeat_datapoint": false, "parallel_samples": 1, "moving_baseline": Infinity, "reference_kl_weight": 0.1}
{"Batch Index": 0, "Task Type": "arithmetic", "Example": {"Question": "60 + 54 + 78 + 96 + 24 + 85 + 72 + 95 + 89 + 13 + 3 + 36 + 8 + 80 + 54", "Actor Reasoning": " 75 + 72 + 80", "Critic Reasoning": "\n\nThe problem is", "Answer": "847", "Contains Answer": 0.0}, "Training Metrics": {"Loss": -0.3203125, "Policy Gradient Loss": 0.86328125, "Actor Reasoning Log Probs": -2.765625, "Critic Reasoning Log Probs": -2.8125, "Actor Answer Log Probs": -6.5625, "Critic Answer Log Probs": -6.875, "KL": 0.003753662109375, "KL Type": "Weighted KL", "PPO Ratio": 1.046875, "PPO Clipped Ratio": 1.046875, "Advantage": 0.3125, "Normalized Reward": 0.3125, "Raw Loss": -0.3203125, "Raw Policy Gradient Loss": 0.86328125, "Raw First Loss": -0.3203125, "Raw First Policy Gradient Loss": 0.86328125, "First Loss": -0.3203125, "First Policy Gradient Loss": 0.86328125, "First Actor Reasoning Log Probs": -2.765625, "First Critic Reasoning Log Probs": -2.8125, "First Actor Answer Log Probs": -6.5625, "First Critic Answer Log Probs": -6.875, "First KL": 0.003753662109375, "First KL Type": "Weighted KL", "First Advantage": 0.3125, "First Normalized Reward": 0.3125, "Gradient Norm": 0.0, "Active Samples": {"Count": 1, "Fraction": 1.0}}, "EI Metrics": {"Use EI": null, "EI Enabled": false, "Mean Previous Advantage": 0.3125, "Std Previous Advantage": 0.0, "Threshold": null}, "Hyperparameters": {"Batch Size": 1, "CoT Length": 5, "Temperature": 1.0, "Use PPO": true}}
