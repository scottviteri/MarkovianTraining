{"task_type": "arithmetic", "model_type": "gpt2", "resume": false, "use_ei": null, "use_ppo": false, "cot_length": 50, "r": 0.9, "temperature": 1.0, "question_length": 50, "target_length": 50, "kl_penalty": 0.1, "gradient_accumulation_steps": 1, "batch_size": 8, "normalize_loss": true, "lr": 0.0001, "num_batches": 2, "ppo_epsilon": 0.2, "checkpoint_frequency": null, "weight_verification_freq": 10, "enable_weight_verification": false, "lora_rank": 8, "lora_alpha": 16, "debug_repeat_datapoint": false, "parallel_samples": 1, "moving_baseline": 10, "reference_kl_weight": 0.1}
{"Batch Index": 0, "Task Type": "arithmetic", "Example": {"Question": "80 + 94 + 54 + 34 + 28 + 91 + 77 + 29 + 76 + 8 + 57 + 5 + 13 + 16 + 86", "Actor Reasoning": " * = 24 * ( 24 + 56 ); * = 3 * ( 4 * 57 ); * = 1 * 4 * 56 + 5 + 6 + 6 + 15 + 60\nYou will be given an arithmetic problem, which you have 50 tokens to", "Critic Reasoning": "\n\nThe problem is:\n\nThe problem is:\n\nThe problem is:\n\nThe problem is:\n\nThe problem is:\n\nThe problem is:\n\nThe problem is:\n\nThe problem is:\n\n", "Answer": "748", "Contains Answer": 0.0}, "Training Metrics": {"Loss": 2.65625, "Policy Gradient Loss": 2.65625, "Actor Reasoning Log Probs": -2.421875, "Critic Reasoning Log Probs": -2.4375, "Actor Answer Log Probs": -8.6875, "Critic Answer Log Probs": -9.875, "KL": 0.00274658203125, "KL Type": "Weighted KL", "actor_critic_kl": 0.0274658203125, "reference_kl": 0.028076171875, "weighted_kl": 0.00274658203125, "reference_kl_penalty": 0.0028076171875, "PPO Ratio": 1.0078125, "PPO Clipped Ratio": 1.0078125, "Advantage": 1.1796875, "Normalized Reward": 1.1796875, "Raw Loss": 2.65625, "Raw Policy Gradient Loss": 2.65625, "Gradient Norm": 0.0, "Active Samples": {"Count": 8, "Fraction": 1.0}}, "EI Metrics": {"Use EI": null, "EI Enabled": false, "Mean Previous Advantage": 1.1796875, "Std Previous Advantage": 2.652421474456787, "Threshold": null}, "Hyperparameters": {"Batch Size": 8, "CoT Length": 50, "Temperature": 1.0, "Use PPO": false}}
{"Batch Index": 1, "Task Type": "arithmetic", "Example": {"Question": "42 + 48 + 17 + 8 + 11 + 45 + 24 + 25 + 33 + 22 + 96 + 75 + 11 + 10 + 25", "Actor Reasoning": "\nNumber 12 (x) represents the same Number 23 (y) \u2013 x represents the same Number 24 (z) \u2013 4 represents the same Number 1 = 1 + 2 = 2 + 3 = 3 + 5 = 5 + 5-6 =", "Critic Reasoning": "\n\nThe problem is a simple one, but it is a problem that can be solved in a few minutes.\n\nThe problem is a simple one, but it is a problem that can be solved in a few minutes. The problem is a", "Answer": "492", "Contains Answer": 0.0}, "Training Metrics": {"Loss": -0.6015625, "Policy Gradient Loss": -0.6015625, "Actor Reasoning Log Probs": -2.890625, "Critic Reasoning Log Probs": -2.890625, "Actor Answer Log Probs": -6.875, "Critic Answer Log Probs": -7.5625, "KL": 0.0032806396484375, "KL Type": "Weighted KL", "actor_critic_kl": 0.03271484375, "reference_kl": 0.033203125, "weighted_kl": 0.0032806396484375, "reference_kl_penalty": 0.003326416015625, "PPO Ratio": 1.015625, "PPO Clipped Ratio": 1.015625, "Advantage": -0.255859375, "Normalized Reward": 0.66796875, "Raw Loss": -0.6015625, "Raw Policy Gradient Loss": -0.6015625, "Gradient Norm": 0.0, "Active Samples": {"Count": 8, "Fraction": 1.0}}, "EI Metrics": {"Use EI": null, "EI Enabled": false, "Mean Previous Advantage": 0.462371826171875, "Std Previous Advantage": 2.074159622192383, "Threshold": null}, "Hyperparameters": {"Batch Size": 8, "CoT Length": 50, "Temperature": 1.0, "Use PPO": false}}
