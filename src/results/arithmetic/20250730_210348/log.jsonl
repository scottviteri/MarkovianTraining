{"task_type": "arithmetic", "model_type": "gpt2", "resume": false, "use_ei": null, "use_ppo": true, "cot_length": 5, "r": 0.9, "temperature": 1.0, "question_length": 50, "target_length": 50, "kl_penalty": 0.1, "gradient_accumulation_steps": 1, "batch_size": 1, "normalize_loss": true, "lr": 0.0001, "num_batches": 1, "ppo_epsilon": 0.2, "checkpoint_frequency": null, "weight_verification_freq": 10, "enable_weight_verification": false, "lora_rank": 8, "lora_alpha": 16, "debug_repeat_datapoint": false, "parallel_samples": 1, "moving_baseline": Infinity, "reference_kl_weight": 0.1, "critic_noise_scale": 0.01}
{"Batch Index": 0, "Task Type": "arithmetic", "Example": {"Question": "87 + 55 + 61 + 36 + 62 + 93 + 96 + 72 + 64 + 85 + 73 + 56 + 17 + 30 + 59", "Actor Reasoning": " Since the number of tokens", "Critic Reasoning": "\n\nThe problem is", "Answer": "946", "Contains Answer": 0.0}, "Training Metrics": {"Loss": -1.1484375, "Policy Gradient Loss": 2.515625, "Actor Reasoning Log Probs": -2.171875, "Critic Reasoning Log Probs": -2.171875, "Actor Answer Log Probs": -6.28125, "Critic Answer Log Probs": -7.4375, "KL": 0.003936767578125, "KL Type": "Weighted KL", "PPO Ratio": 1.0, "PPO Clipped Ratio": 1.0, "Advantage": 1.15625, "Normalized Reward": 1.15625, "Raw Loss": -1.1484375, "Raw Policy Gradient Loss": 2.515625, "Raw First Loss": -1.1484375, "Raw First Policy Gradient Loss": 2.515625, "First Loss": -1.1484375, "First Policy Gradient Loss": 2.515625, "First Actor Reasoning Log Probs": -2.171875, "First Critic Reasoning Log Probs": -2.171875, "First Actor Answer Log Probs": -6.28125, "First Critic Answer Log Probs": -7.4375, "First KL": 0.003936767578125, "First KL Type": "Weighted KL", "First Advantage": 1.15625, "First Normalized Reward": 1.15625, "Gradient Norm": 0.0, "Active Samples": {"Count": 1, "Fraction": 1.0}}, "EI Metrics": {"Use EI": null, "EI Enabled": false, "Mean Previous Advantage": 1.15625, "Std Previous Advantage": 0.0, "Threshold": null}, "Hyperparameters": {"Batch Size": 1, "CoT Length": 5, "Temperature": 1.0, "Use PPO": true}}
