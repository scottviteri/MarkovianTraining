{"task_type": "arithmetic", "model_type": "gpt2", "resume": false, "use_ei": null, "use_ppo": true, "cot_length": 5, "r": 0.9, "temperature": 1.0, "question_length": 50, "target_length": 50, "kl_penalty": 0.1, "gradient_accumulation_steps": 1, "batch_size": 1, "normalize_loss": true, "lr": 0.0001, "num_batches": 1, "ppo_epsilon": 0.2, "checkpoint_frequency": null, "weight_verification_freq": 10, "enable_weight_verification": false, "lora_rank": 8, "lora_alpha": 16, "debug_repeat_datapoint": false, "parallel_samples": 1, "moving_baseline": Infinity}
{"Batch Index": 0, "Task Type": "arithmetic", "Example": {"Question": "32 + 52 + 34 + 81 + 20 + 71 + 57 + 88 + 97 + 64 + 47 + 77 + 29 + 59 + 56", "Actor Reasoning": " You have an arithmetic problem", "Critic Reasoning": "\n\nThe problem is", "Answer": "864", "Contains Answer": 0.0}, "Training Metrics": {"Loss": -0.125, "Policy Gradient Loss": 0.25390625, "Actor Reasoning Log Probs": -2.03125, "Critic Reasoning Log Probs": -2.03125, "Actor Answer Log Probs": -6.1875, "Critic Answer Log Probs": -6.3125, "KL": 0.0, "KL Type": "Raw KL", "PPO Ratio": 1.0, "PPO Clipped Ratio": 1.0, "Advantage": 0.125, "Normalized Reward": 0.125, "Raw Loss": -0.125, "Raw Policy Gradient Loss": 0.25390625, "Raw First Loss": -0.125, "Raw First Policy Gradient Loss": 0.25390625, "First Loss": -0.125, "First Policy Gradient Loss": 0.25390625, "First Actor Reasoning Log Probs": -2.03125, "First Critic Reasoning Log Probs": -2.03125, "First Actor Answer Log Probs": -6.1875, "First Critic Answer Log Probs": -6.3125, "First KL": 0.0, "First KL Type": "Raw KL", "First Advantage": 0.125, "First Normalized Reward": 0.125, "Gradient Norm": 0.0, "Active Samples": {"Count": 1, "Fraction": 1.0}}, "EI Metrics": {"Use EI": null, "EI Enabled": false, "Mean Previous Advantage": 0.125, "Std Previous Advantage": 0.0, "Threshold": null}, "Hyperparameters": {"Batch Size": 1, "CoT Length": 5, "Temperature": 1.0, "Use PPO": true}}
