"""
# Experiment outline:
## Goal:
    1. Measure a decrease in the loss of a model on a particular high quality dataset 
        when a helpful message is prepended to the prompt.
## Hypothesis:
    1. There are strings you can pre-pend to a message that will decrease the loss of the model
    2. Downstream hypothesis if this works: We can see if a LM is able to figure out how to provide such helpful and honest messages.
## Method:
    1. Train a model on a dataset
    2. Measure the loss of the model on each batch of the dataset with and without a prompt
## Evaluation and Experiments:
    1. Look for potential complications by plotting per token loss as a function of token position.
    2. Evaluate null hypothesis: just a random sentence prepended of a fixed length.
    3. Evaluate hypotheses: a) The first sentence from the batch. b) The first sentence wrapped in a message explaining this is a
        helpful message. c) A model generated summary of the sentences. - Helpful message generated by gpt4 as upper bound on competence
"""

import torch
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from datasets import load_dataset

def main():
    causal_lm = GPT2LMHeadModel.from_pretrained("gpt2")
    print("Loaded causal LM")
    print(causal_lm)
    causal_lm_tokenizer = GPT2TokenizerFast.from_pretrained("gpt2")

    # load dataset
    # here we load a small dataset from https://huggingface.co/datasets/allenai/c4
    c4_subset = load_dataset("allenai/c4", data_files="en/c4-train.00000-of-01024.json.gz")
    print("Loaded dataset")
    print(c4_subset)


if __name__ == "__main__":
    main()